---
title: Graph Algorithms
date: 2020-05-04
---

# Graph Algorithms

## Topological Sort

Boring. Count the number of in edges and store in a hash. Each round, pick a vertex with no in edges. That's the next vertex. Decrement the vertices which have an in edge here. `O(|V| + |E|)`.

## DFS, BFS, IDDFS

DFS can be implemented with a stack, BFS with a queue.

BFS is optimal, and will eventually find a solution if it exists (_complete_). DFS is not necessarily optimal, and in an infinite graph can go down a wrong path forever; it also has problems with loops.

DFS is much better at memory usage: it runs proportional to depth of the tree, while BFS uses `O(b^d')` memory, where `d'` is depth of the best solution.

You can fix the BFS space problem by running iterative-deepening DFS, which just performs a depth-limited DFS search for increasing depths. This is a complete and optimal solution. Also, since most vertices are at the last level, this still runs in `O(b^d')` time!

**Backtracking**

- You can give up on a branch if you realize it can't possibly lead to success.

## Uninformed Shortest Path: Dijkstra and Floyd-Warshall

Dijkstra's algorithm just grows paths by adding path extensions one at a time. There are three approaches:

- Keep track of best paths to all `V` vertices: `O(E + V**2)`.
- Use a binary heap: `O((E + V) * log(V))`.
  - Worse for dense graphs.
- Use a Fibonacci heap: `O(E + V * log(V))`.
  - Updates are cheap!
  - Best of both worlds, except probably slower than either because Fib heaps are slow and complicated.

If you want to find all-pairs shortest paths, you can run Dijkstra's `V` times. However, if you have a dense graph, you might also use the Floyd-Warshal algorithm:

- Dynamic programming algorithm that loosens a constraint of only traveling through a subset of vertices.
- `V` runs: each time, you select a vertex, updating `V**2` paths.

In a dense graph, Floyd-Warshall has better practical performance than Dijkstra. But for a sparse graph the repeated Fibonacci Dijkstra is better. _Except that Floyd-Warshall can deal with negative edges_.

Since I don't give a shit, I don't talk about _Bellman-Ford_ or _Johnson's Algorithm_, which can handle **negative cycles**. Fuck that.

In the case of trees with a branching factor of `b`, then the longest path you must consider is of length `C/eps`, where `eps` is a lower bound on the cost of an edge, while `C` is the cost of the best path. Therefore, we can take `V=C/eps`.

## Informed Search: A*

**A\*** is a souped-up Dijkstra's algorithm. It requires an _admissable heuristic_: one which is optimistic about the distance from a vertex to the target. In the priority queue, we take into acount not only the path's cost, but the expected further distance to travel to a goal node.

Generally speaking, this is the same as Dijkstra, which just has a heuristic of `0`. The algorithm is complete and optimal. It will give up on bad paths eventually as it slowly realizes the heuristic was optimistic.

**Correction:** You need a _consistent_ (AKA monotone) heuristic. This one has the property that:

h(n) <= c(n, n') + h(n')

for all successors `n'` of `n`. The reason this is important is that when you expand a node, you need to know that you were considering not just what you think is the probable best path to the target, but in fact _the best path to that interior node_.

**Result**: When the search is in a tree AND the error of the heuristic function is logarithmic, then the time complexity is polynomial! **TODO2: Prove me!**

Note that A* is optimal for any heuristic searching out from the root, because it needs to consider exactly those paths it considers, lest it miss a shortcut to the target. Of course, there are other possible algorithms that don't just start from the root...

NB: A heuristic that dominates another (`h_2(n) > h_1(n)` for all `n`) will yield better performance, assuming of course it is still acceptable.

## IDA*

Both Dijkstra and A* both suffer from very large memory requirements. Another approach is to modify IDDFS to use a heuristic. In this case, you set a `bound` for total path cost; you then search in a DFS manner, abandoning a path when the heuristic total cost `g(a) + h(a)` greater than the bound.

Like IDDFS, this runs in multiple rounds. Start the bound at zero. Abandon paths as above; but also keep track of the cost of the minimum abandoned path. In the next round, use this cost as the new bound to ensure progress.

```ruby
class IDAStarSolver
  def run(source)
    bound = h(root)
    loop do
      result = search(root, 0, bound)
      return result[:found] if result.has_key?(:found)
      bound = result [:abandonment_cost]
    end
  end

  def search(node, cost, bound)
    if cost + h(node) > bound
      # Abandon this route!
      return { abandonment_cost: cost + h(node) }
    end

    return { found: node } if is_goal?(node)

    abandonment_cost = nil
    node.out_edges.each do |edge|
      new_cost = cost + edge.cost
      result = search(edge.to_vertex, new_cost, bound)

      # May have found it!
      return result if result.has_key?(:found)
      # May have given up!
      if abandonment_cost.nil? || result[:abandonment_cost] < abandonment_cost
        abandonment_cost = result[:abandonment_cost]
      end
    end

    return abandonment_cost
  end
end
```

This returns an optimal path, with much reduced memory usage (proportionate) to length path. However, it may have higher computational overhead because of the necessity of revisiting nodes. It also in some sense doesn't use enough memory; it just remembers a ceiling heuristic value.

An alternative is **SMA\***, which expands the graph at the leaves in an `A*` manner. When it runs out of space, it drops the low cost leaf, writing into its parent that we should return when we've explored all nodes of lower cost. The parent can be added to the "leaf" set. In this way, we don't need to keep revisiting early parts of the tree as we do in `IDA*`.

## Bidirectional Search

Start from both ends and work toward the others. When you link up, you have a path. You can use BFS or IDDFS in which case the result will be optimal. You need to keep one of the fringes in memory, so space usage is `O(b^d)` if we're talking a tree.

On the other hand, you can use A* targeting the other source. It seems that the result may not be optimal. There is also a concept of "front-to-front" search where a heuristic exists to move toward the *front*, and not the *back*. This may be optimal. However, this is pretty expensive.

## Minimax, Alpha-Beta Pruning

Minimax strategy is to make the best move, assuming your opponent makes the worst move for you and you respond with the best. Basically, you try to maximize, then they try to minimize...

You can of course do this to completion with a `+1` for winning and a `-1` for losing (and maybe a `0` for drawing). This of course doesn't work for deep game trees, so we use heuristics to guide the search. For instance, look 12 moves ahead and then apply the heuristic.

Imagine that the minimizing player sees they can force a loss by taking the first branch of the move tree from a given position. Then there is no need to consider the other branches. Alpha-Beta pruning extends this logic. If the maximizing player sees they can force a score of `x` on the first branch, then they need to check the other branches. However, as soon as the minimizing player realizes they can force a score less than `x`, they can abandon this path, because things can only get worse for the maximizer, and thus they will not take this path.

Let alpha be the maximum score that the maximizer knows they can force, where beta is the minimum score that the minimizer knows they can force. As the search plays out, alpha and beta will approach each other until they become equal. To start, alpha may be `-1` and `+1`, since we know that the maximizer can't do worse that lose, and vice-versa.

```ruby
def search(node, player, depth, alpha, beta)
  return { path: [node], heuristic: h(node) } if depth == 0

  if player == true
    # Try to maximize!
    max_path, max_path_score = nil, nil
    node.children.each do |child|
      path, path_score = search(
        child,
        false,
        depth - 1,
        alpha,
        beta
      ).values_at(:path, :heuristic)

      next if path.nil?

      # Is this the best move we've seen so far?
      if max_path_score.nil? || path_score > max_path_score
        max_path, max_path_score = path, max_path_score
      end

      # If considering a branch where the opponent can force a result
      # worse than alpha, forget it, since this is the better option.
      if alpha < path_score
        alpha = path_score

        # Beta was previously set to the worst result the opponent
        # could force. But now we see that if the opponent must never
        # allow us to move to node, because then the maximizer could
        # force a better result.
        return { abandoned: true } if beta < alpha
      end
    end

    return { path: max_path, heuristic: max_path_score }
  else
    # Analogous!
  end
end
```

## Minimum Spanning Tree: Prim's Algorithm

Just stupid Dijkstra's. Doesn't take into account of existing path, just the cost of the next edge. Same performance characteristics.

Kruskal's Algorithm is apparently more performant in sparse graphs, though has same time bounds. It uses union-find datastructure which seems boring.

BorÅ¯vka's algorithm is apparently very parallelizable. Could actually be interesting. **Todo**

## More Graph Problems

- Johnson's Algorithm allows faster all-pairs shortest path _on sparse graphs_.
- Min cut
- Smallest max-edge path
- Largest min-edge path
- K-shortest paths
- Clique detection
- Embedding
- Strongly Connected components
